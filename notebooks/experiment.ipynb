{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from src import BASE_DIR\n",
    "\n",
    "from src.models.dcgan_lsun import *\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from src.utils.visualization import create_grid_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating and visualizing the internals of the networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Walking in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2405)\n",
    "\n",
    "# noise\n",
    "num_noise = 11\n",
    "noises = torch.randn(num_noise, 100)\n",
    "G = Generator(ngf=128)\n",
    "try:\n",
    "    G.load_state_dict(torch.load(os.path.join(BASE_DIR,'models/LSUN/20230510_1855_s1000000_bs128_ep5/gen_params_5.pth')))\n",
    "except FileNotFoundError:\n",
    "    print(\"Not exist model params. You can train model with LSUN dataset or get pretrained param from this link: https://drive.google.com/file/d/16hnQmRKY4x3gPFI2lxydqAtakmnfVISm/view?usp=sharing\")\n",
    "\n",
    "\n",
    "interpolated_list = []\n",
    "# interpolation between 2 noise point\n",
    "with torch.no_grad():\n",
    "    for i in range(num_noise - 1):\n",
    "        z1, z2 = noises[i], noises[i+1]\n",
    "        for coef in np.linspace(0,1,10):\n",
    "            interpolated = (1 - coef) * z1 + coef * z2\n",
    "            interpolated_list.append(interpolated)\n",
    "\n",
    "images = G(torch.stack(interpolated_list))\n",
    "grid_image = create_grid_image(images=images, nimage_row=10, save=True, path_to_save=os.path.join(BASE_DIR,'reports/LSUN/interpolated.png'))\n",
    "plt.imshow(grid_image)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing discriminator features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from src.utils. guided_backpropgation import GuidedBackprop\n",
    "from src.data.LSUN.transforms import *\n",
    "\n",
    "listdir = os.listdir('../../DCGAN/data/LSUN/bedroom_train_data/')\n",
    "num_image = 10\n",
    "paths = listdir[:num_image]\n",
    "\n",
    "model = Discriminator()\n",
    "model.load_state_dict(torch.load(os.path.join(BASE_DIR, 'models/LSUN/20230510_1855_s1000000_bs128_ep5/dis_params_5.pth')))\n",
    "\n",
    "base_model = Discriminator()\n",
    "\n",
    "learned_gbp = GuidedBackprop(model)\n",
    "base_gbp = GuidedBackprop(base_model)\n",
    "learned_gbp.register_hooks()\n",
    "base_gbp.register_hooks()\n",
    "\n",
    "grid = []\n",
    "\n",
    "for path in paths:\n",
    "    image = Image.open(os.path.join(BASE_DIR,'data/LSUN/bedroom_train_data/', path))\n",
    "\n",
    "    composed = transforms.Compose([\n",
    "        CenterCrop(),\n",
    "        ReScale(64),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image = composed(image)\n",
    "    learned_result = learned_gbp.generate_reconstructed_image(image.unsqueeze(0).requires_grad_())\n",
    "    base_result = base_gbp.generate_reconstructed_image(image.unsqueeze(0).requires_grad_())\n",
    "    grid.extend([image, base_result, learned_result])\n",
    "\n",
    "\n",
    "grid = torch.stack(grid).reshape(num_image,3,*(grid[0].shape)).transpose(1,0).reshape(-1,*(grid[0].shape))\n",
    "grid_image = create_grid_image(grid, nimage_row=10, save=True, path_to_save=os.path.join(BASE_DIR,'reports/LSUN/guided_bp.png'))\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(grid_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
